<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Deepseek V3 &amp; R1 论文解读笔记 技术版 | Neal's Life Gallery </title> <meta name="author" content="Yichen (Neal) Zheng"> <meta name="description" content="Deep Tech-analysis for DeepSeek New Model V3 &amp; R1"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://cardinalneal.github.io/blog/2025/DSV3R1/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Neal's Life Gallery </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deepseek V3 &amp; R1 论文解读笔记 技术版</h1> <p class="post-meta"> Created in March 01, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>   ·   <a href="/blog/category/tech"> <i class="fa-solid fa-tag fa-sm"></i> Tech</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="前言">前言</h2> <p>大语言模型中 在实用方面 分为两种模型，</p> <p>一种是 通用模型，一种是 推理模型 推理模型是在通用模型基础上进行 加强（核心技术），</p> <p>推理模型的核心技术： 强化学习，RL； 推理规模（inference scaling）</p> <h3 id="通用模型">通用模型</h3> <p>实例：GPT-4</p> <p>运行原理：预测下一个词（概率预测）</p> <p>特点：快速</p> <p>比较依赖提示词补偿，进行显式引导</p> <p>优势领域：创意</p> <p>缺陷：幻觉，也就是瞎说</p> <h3 id="推理模型">推理模型</h3> <p>实例：GPT-o3</p> <p>运行原理：会对你内容进行思考，也就是CoT</p> <p>优势：逻辑密度高</p> <p>优势领域：逻辑推理</p> <p>缺点：不要使用”启发式“（cosplay）提示词</p> <hr> <h1 id="deepseek-v3">DeepSeek V3</h1> <h2 id="核心特点">核心特点</h2> <p><code class="language-plaintext highlighter-rouge">DeepSeek-V3</code></p> <ul> <li> <strong>架构</strong>：MoE（Mixture of Experts），总参数量 671B，每次激活 37B。</li> <li> <strong>关键技术</strong>： <ul> <li> <strong>Multi-head Latent Attention (MLA)</strong>：减少推理计算资源。</li> <li> <strong>DeepSeekMoE</strong>：优化训练和推理成本。</li> <li> <strong>FP8 混合精度</strong>：取代 FP32，提升效率。</li> <li> <strong>训练策略</strong>：Multi-token prediction + auxiliary-loss-free。</li> <li> <strong>预训练</strong>：稳定，没有 loss spike &amp; roll back</li> </ul> </li> </ul> <p><strong>MoE 与 Dense 模型区别</strong></p> <ul> <li> <strong>MoE</strong>：推理时只激活一部分相关参数。</li> <li> <strong>Dense</strong>：推理时激活所有参数。</li> </ul> <h2 id="architecture">Architecture</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DSV3R1_1-480.webp 480w,/assets/img/DSV3R1_1-800.webp 800w,/assets/img/DSV3R1_1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DSV3R1_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="multi-head-latent-attentionmla">Multi-head Latent Attention(MLA)</h3> <aside> 💫 - 作用：在 inference 的时候 使得计算资源进一步减少 - 基于：Attention &amp; KV cache 上面的改进 </aside> <p>Attention 本质上是计算 token 之间的 correlation</p> <p>由于 大部分大语言模型 都采用decoder 架构，所以 autoregressive 所以就是token by token, 相当于 运行decoder N 遍，KV cache 就是一个拿空间换时间的方法。</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DSV3R1_2-480.webp 480w,/assets/img/DSV3R1_2-800.webp 800w,/assets/img/DSV3R1_2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DSV3R1_2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>MLA 的基本思想</p> <ol> <li>用一个低维度的 C 去代替 原本的 K &amp; V， 通过 C 去搭配 W_k &amp; W_v 去还原 原本的K &amp; V</li> <li>但是这个会让 RoPE 失效</li> </ol> <p>Decoupled Rotary Position Embedding (RoPE) - 一种 Position Embedding， 介于 absolute position embedding &amp; relative position embedding 之间，</p> <p>但这里就会让 KV cache 失效， 所以 在 采用 architecture 中最上面图片 的右下 Attention 结构</p> <h3 id="deepseekmoe-architectures">DeepSeekMoE architectures</h3> <aside> ➡️ 是整体架构，主要针对的是training &amp; inference 的 cost 优化，具体改动： 1. 增加 **Expert** 数量，减少单个 Expert 的参数量，从而保持总参数量相近。 2. 将部分 Expert 变为通用 Expert（即通才），提升模型的泛化能力。 3. 在 **sigmoid** 前增加 **bias term**，用于调节负载（仅在训练时使用）。 </aside> <p><strong>MoE 架构</strong></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DSV3R1_3-480.webp 480w,/assets/img/DSV3R1_3-800.webp 800w,/assets/img/DSV3R1_3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DSV3R1_3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>MoE 架构：</p> <ul> <li> <strong>Dense MoE</strong>：所有 FFN（Feed-Forward Network）按比例加权平均。</li> <li> <strong>Sparse MoE</strong>：选择 Top K 的 Expert 进行加权平均，通常选择 Sparse MoE 以减少成本。</li> </ul> <p><strong>问题</strong>：在不同的Expert 中间 区分度不是特别大，且有可能会有重合冗余的</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DSV3R1_4-480.webp 480w,/assets/img/DSV3R1_4-800.webp 800w,/assets/img/DSV3R1_4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DSV3R1_4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>基于上述问题，DeepSeekMoE 架构</p> <p><strong>结构改进</strong>:</p> <ul> <li>专家数量倍增（2N个微专家）</li> <li>设置共享专家（Common Experts）</li> <li>用 数量 交换 质量，Various 变小了，就不会太容易过拟合</li> </ul> <h3 id="auxiliary-loss-free">Auxiliary-loss-free</h3> <aside> 💫 **问题**：MoE 模型 在training中非常可能出现负载不平衡 (**Load Balance**) **解决方法：**通常 是使用 **Loss Control**, 但作者选择使用 **Loss Free** </aside> <p>MoE 模型在训练过程中可能出现 <strong>负载不平衡</strong> 问题，即某些 Expert 被过度使用，导致富的更富，穷的更穷。传统方法通过增加额外的 Loss Control 来平衡负载，但这种<strong>Loss 可能是错误</strong>的！</p> <p>DeepSeek 采用 <strong>loss free</strong> 的方法</p> \[g'_{i,t} =\begin{cases}s_{i,t} + b_i &amp; \text{if } s_{i,t} + b_i \in \text{Top}_k\left( \{ s_{j,t} + b_j \mid 1 \leq j \leq N_r \}, K_r \right), \\0 &amp; \text{otherwise.}\end{cases}\] <p>通过在 softmax 前增加 <strong>bias term</strong> 来手动调节负载（token越多，则 b 越小，从而输出的softmax 越小。），从而在不影响损失的情况下实现负载平衡。</p> <h3 id="multi-token-prediction">Multi-token prediction</h3> <aside> ➡️ 增强模型推理性能 &amp; 增加训练效率 </aside> <p><strong>LLM Training</strong></p> <ul> <li> <strong>短视</strong>：模型训练时通常会依赖较短期的目标（即单个token的预测），缺乏对长时间步的全局视野。</li> </ul> <p><strong>LLM Inference</strong></p> <ul> <li> <strong>自回归模型</strong>：LLM的推理是<strong>token by token</strong>的逐步生成，每生成一个token就进行一次预测，并以此为基础继续生成下一个token。</li> <li> <strong>缺乏Ground Truth</strong>：在推理阶段，模型没有像训练阶段那样有ground truth去进行校正。</li> <li> <strong>慢</strong>：推理过程由于是逐步生成，因此速度较慢，尤其是当生成长文本时，推理效率低下。</li> </ul> <p><strong>思路</strong>： 通过在 Inference 过程中采用 <strong>Speculative Decoding（猜测性解码）</strong>，可以提高生成的速度并减少逐token生成的时间开销。即 增加一个小模型，去快速预测一个token 然后由大模型进行验证</p> <p><strong>必要条件</strong></p> <ol> <li> <strong>Quick Guess (快速猜测)</strong>： <ul> <li>需要在推理过程中进行快速的初步猜测，从而减少推理时间。</li> </ul> </li> <li> <strong>Cheap Verification (廉价验证)</strong>： <ul> <li>对每个猜测结果进行快速且低成本的验证，确保最终的预测结果准确。</li> </ul> </li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DSV3R1_5-480.webp 480w,/assets/img/DSV3R1_5-800.webp 800w,/assets/img/DSV3R1_5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DSV3R1_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>DeepSeek 采用了 把 Causal Chain 从 推理阶段 放进了 训练阶段，在训练过程中 增强了模型的远视能力，在推理过程中 则 直接拿掉</p> <h1 id="deepseek-r1">Deepseek R1</h1> <aside> 在理解了基础模型与推理模型的区别后，我们将深入解析 R1 这一推理模型。R1 的论文标题为《Incentivizing Reasoning Capability》，其核心思想是通过激励机制增强模型的推理能力。相较于 V3，R1 的设计思路更为直观。 </aside> <h2 id="背景">背景</h2> <h3 id="1-rl">1 RL</h3> <p><strong>强化学习（RL）</strong> 是一种对泛化能力有显著帮助的学习范式，相当于一种通过激励机制（奖励和惩罚）来优化模型行为的学习范式。模型在回答正确时获得奖励，从而被鼓励自主探索。在 R1 的训练过程中，激励机制主要关注模型是否进行思考以及结果的正确性。</p> <ul> <li>reward <ul> <li>是 稀疏的</li> <li>如何去 define 一个好的reward</li> </ul> </li> <li>dynamic interact with environment</li> <li>explore v.s. exploit</li> </ul> <h3 id="2-agi">2 AGI</h3> <p><strong>通往 AGI 的道路</strong>：推理模型的出现源于对通用人工智能（AGI）的追求。AGI 的核心在于模型的泛化能力，而非简单的死记硬背。因此，模型需要具备自主思考和推理的能力。</p> <h3 id="3-llm-training">3 LLM Training</h3> <ol> <li> <p>训练范式</p> <p>原先openai 范式：</p> <ol> <li>Pre-train : 在这个 过程中，数据质量很关键。</li> <li>Post-train <ol> <li>SFT：这个过程中，数据质量也很关键</li> <li>human preference → reward model</li> <li>reward model → RL (PPO)</li> </ol> </li> </ol> <p>R1 的纯RL 是只有rule-based + final reward，也就是像 code &amp; math</p> </li> </ol> <ul> <li>要训练 LLM 通过 RL 做题，要有 精准的 Reward</li> <li>不要采用结构化的方法，最终限制了模型的效果，要让模型 探索思考方式</li> <li>思考过程中包含了搜索过程，允许犯错 <ol> <li>scaling law</li> </ol> <p>General = scale up + less structure model</p> <p>但是 scale 也不能无限大，会遇到各种各样的问题，<code class="language-plaintext highlighter-rouge"> 系统问题 </code> 尤其突出，e.g. loss spike (loss突然增大) ；其次就是越来越容易听不懂人话</p> </li> </ul> <ol> <li> <p>emergent ability 涌现</p> <p>就是指 大模型参数超过一定的阈值之后，大模型的性能 会突然从量变到质变。</p> <p>在 R1 这篇文章中也得到了证实。 R1的这套方法在小模型上面没有效果</p> </li> </ol> <h2 id="architecture-1">Architecture</h2> <h3 id="复现-deepseek-r1-的aha-moment"><strong>复现 DeepSeek R1 的「Aha Moment」</strong></h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                                                              ***“左脚踩右脚”***
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/DSV3R1_5-480.webp 480w,/assets/img/DSV3R1_5-800.webp 800w,/assets/img/DSV3R1_5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/DSV3R1_5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ol> <li> <strong>基础模型</strong>：<code class="language-plaintext highlighter-rouge">DeepSeek V3</code>（MoE 模型）。</li> <li> <strong>纯 RL 训练</strong>：通过纯 RL（数学和代码）训练生成 <code class="language-plaintext highlighter-rouge">DS-R1-Zero</code> 模型。 <ul> <li>优点：极强的推理能力。</li> <li>缺点：可读性差，语言混乱。</li> <li>生成 <strong>SFT(CoT) data1</strong> 作为冷启动数据。</li> </ul> </li> <li> <strong>冷启动 + RL 训练</strong>：<code class="language-plaintext highlighter-rouge">DeepSeek V3</code> 使用 <strong>data1</strong> 进行冷启动，再进行 纯RL训练，得到<code class="language-plaintext highlighter-rouge">R1-checkp1</code> 然后经过一致性 RL 训练生成 <code class="language-plaintext highlighter-rouge">R1-checkp2</code> 。 <ul> <li>一致性指的是语言的一致性，<code class="language-plaintext highlighter-rouge">R1-checkp2</code> 解决了语言混杂问题。</li> <li> <code class="language-plaintext highlighter-rouge">R1-checkp2</code> 生成更高质量的 <strong>SFT(CoT) data2</strong> </li> </ul> </li> <li> <strong>基模型优化</strong>：<code class="language-plaintext highlighter-rouge">DeepSeek V3</code> 通过 <strong>SFT(CoT) data2</strong> 训练生成 新的 <code class="language-plaintext highlighter-rouge">DeepSeek V3</code> <ul> <li>生成 通用知识 <strong>SFT(Knowledge) data3</strong> </li> </ul> </li> <li> <strong>最终模型</strong>：<code class="language-plaintext highlighter-rouge">DeepSeek V3</code> 使用 <strong>data 2</strong> + <strong>data3</strong> 进行冷启动，结合 RL 和人类偏好训练，生成 <code class="language-plaintext highlighter-rouge">DeepSeek R1</code>。</li> </ol> <h3 id="gpro">GPRO</h3> <h2 id="r1-的破圈行业影响与未来展望">R1 的破圈：<strong>行业影响与未来展望</strong> </h2> <p><strong>R1 突破的基础是真正的实力。</strong>性能确实非常强大，懂的都懂。当然，DeepSeek 做到的还不止这些，他还做了很多尝试，也分享了全球的AI行业</p> <p>R1 的成功不仅在于其强大的性能，更在于它解决了行业面临的难题，并为学术界指明了发展方向。如果你是研究人员或者大模型公司，你会觉得这东西想我所想，急我所急。</p> <p>DeepSeek 的贡献不仅限于 R1，还包括以下几点：</p> <ol> <li> <strong>蒸馏实验</strong>：通过蒸馏实验证明了高质量 reasoning CoT 能够激发现有模型的能力。这一发现为现有模型的优化提供了新的思路。</li> <li> <strong>创新范式</strong>：R1 证明了「左脚踩右脚」的可行性，为未来几个月到半年内的 RL 领域突破奠定了基础。</li> <li> <strong>AI Infra 的崛起</strong>：全球 AI 基础设施终于找到了值得部署的模型，推动了 AI Infra 的发展。如果 OpenAI 开源，全球 AI Infra 的格局将大不相同。</li> <li> <strong>可控推理时间扩展</strong>：虽然 R1 尝试了 RL，但尚未进行可控的 inference time scaling。这一方向的探索有望进一步提升模型性能。</li> <li> <strong>long2short 推理</strong>：这一概念非常有趣，推理过程不应被视为模型的旁路思考，而是 Next Token Prediction 的一部分。未来，推理过程将更加高效，能够快速聚焦于关键问题。</li> </ol> <p>新的尝试</p> <ul> <li> <strong>基模型的重要性</strong>：即使是通过“左脚踩右脚”的方式提升模型，基模型的质量仍然至关重要。</li> </ul> <h1 id="relative-article">Relative Article</h1> <p><a href="https://mp.weixin.qq.com/s/8ifsQ1eRJpOSHCrFAtAX0A" rel="external nofollow noopener" target="_blank"><strong>万字赏析 DeepSeek 创造之美：DeepSeek R1 是怎样炼成的？</strong></a></p> <p><a href="/assets/pdf/DeepSeekR1_Analysis_Tenction.pdf">万字赏析 DeepSeek 创造之美：DeepSeek R1 是怎样炼成的？丨荐读.pdf</a></p> <p><a href="https://www.youtube.com/watch?v=axlQI7fGn_8&amp;t=0s" rel="external nofollow noopener" target="_blank">https://www.youtube.com/watch?v=axlQI7fGn_8&amp;t=0s</a></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/MarriageAlgo/">暗黑育儿法：一个父亲的社会达尔文主义实践手记</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Hallucinations/">大模型的“幻觉”：是创意的火花还是认知的陷阱？</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/24review-25plan/">2024年我的成长清单📝｜2025我要这样布局🔥</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yichen (Neal) Zheng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>