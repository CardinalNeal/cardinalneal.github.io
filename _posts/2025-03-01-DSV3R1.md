---
layout: post
title: Deepseek V3 and R1 论文解读笔记 技术版
date: 2025-03-01 21:30:13
description: Deep Tech-analysis for DeepSeek New Model V3 and R1
tags: LLM
categories: Tech
---



# Deepseek V3 & R1 论文解读笔记 技术版



# DeepSeek V3

## 核心特点

`DeepSeek-V3`  

- **架构**：MoE（Mixture of Experts），总参数量 671B，每次激活 37B。
- **关键技术**：
    - **Multi-head Latent Attention (MLA)**：减少推理计算资源。
    - **DeepSeekMoE**：优化训练和推理成本。
    - **FP8 混合精度**：取代 FP32，提升效率。
    - **训练策略**：Multi-token prediction + auxiliary-loss-free。
    - **预训练**：稳定，没有 loss spike & roll back


